{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GTvsDWHadbK"
      },
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'), \n",
        "  tf.keras.layers.Dropout(0.2), \n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "#predictions = model(x_train[:1]).numpy()\n",
        "#tf.nn.softmax(predictions).numpy()\n",
        "#loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "#loss_fn(y_train[:1], predictions).numpy()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "model.evaluate(x_test,  y_test, verbose=2)\n",
        "#probability_model = tf.keras.Sequential([  model, tf.keras.layers.Softmax() ])\n",
        "#probability_model(x_test[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O27ZMOgefke"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "#plt.figure()\n",
        "#plt.imshow(train_images[0])\n",
        "#plt.show()\n",
        "train_images , test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=10)\n",
        "\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "probability_model = tf.keras.Sequential([model, \n",
        "                                         tf.keras.layers.Softmax()])\n",
        "predictions = probability_model.predict(test_images)\n",
        "np.argmax(predictions[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr3HJHND4yqa"
      },
      "source": [
        "!pip install -q tensorflow-hub\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "train_data, validation_data, test_data = tfds.load( \n",
        "    name= \"imdb_reviews\", \n",
        "    split=('train[:60%]', 'train[60%:]', 'test'),\n",
        "    as_supervised=True)\n",
        "\n",
        "# from https://www.tensorflow.org/datasets/catalog/overview\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim50/2\", input_shape=[], \n",
        "                           dtype=tf.string, trainable=True))      # choose from https://tfhub.dev/\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data.shuffle(10000).batch(512),\n",
        "                    epochs=10,\n",
        "                    validation_data=validation_data.batch(512),\n",
        "                    verbose=1)\n",
        "\n",
        "results = model.evaluate(test_data.batch(512), verbose=2)\n",
        "\n",
        "for name, value in zip(model.metrics_names, results):\n",
        "  print(\"%s: %.3f\" % (name, value))    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}