{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rRo8oNqZ-Rj"
      },
      "source": [
        "#!pip install -q seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9VNE1HgChwj"
      },
      "source": [
        "dictoo = {}\n",
        "thesetofdata = ()\n",
        "listofcolumns = []\n",
        "\n",
        "\n",
        "\n",
        "dictoo[\"x2\"] = np.random.rand(1000)\n",
        "\n",
        "dictoo[\"x\"] = 10 + 20*np.random.rand(1000)\n",
        "\n",
        "#dictoo[\"x^2\"] =  dictoo[\"x\"]  **2\n",
        "#dictoo[\"x^3\"] =  dictoo[\"x\"] **3\n",
        "#dictoo[\"1/x\"] =  1/ dictoo[\"x\"] \n",
        "#dictoo[\"sinx\"] =  np.sin(dictoo[\"x\"] )\n",
        "#dictoo[\"cosx\"] = np.cos(dictoo[\"x\"] )\n",
        "\n",
        "dictoo[\"y\"] = dictoo[\"x2\"]**2 + dictoo[\"x\"]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReAD0n6MsFK-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fdad2ce-e58f-4690-e9e7-dcde00cab92c"
      },
      "source": [
        "for i in dictoo.keys():\n",
        "  listofcolumns.append(i)\n",
        "\n",
        "thesetofdata = dictoo.values()\n",
        "\n",
        "dataset = pd.DataFrame(data=thesetofdata)\n",
        "dataset = dataset.transpose()\n",
        "dataset.columns = listofcolumns\n",
        "renameedict = {listofcolumns[0]:\"input\", listofcolumns[-1]:\"result\"}\n",
        "dataset = dataset.rename(columns=renameedict)\n",
        "\n",
        "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)\n",
        "#sns.pairplot(train_dataset, diag_kind='kde')\n",
        "#train_dataset.describe().transpose()\n",
        "train_features = train_dataset.copy()\n",
        "test_features = test_dataset.copy()\n",
        "train_labels = train_features.pop('result')\n",
        "test_labels = test_features.pop('result')\n",
        "train_dataset.describe().transpose()[['mean', 'std']]\n",
        "\n",
        "\n",
        "normalizer = preprocessing.Normalization()\n",
        "normalizer.adapt(np.array(train_features))\n",
        "singlevariable = np.array(train_features['input'])\n",
        "singlevariable_normalizer = preprocessing.Normalization(input_shape=[1,])\n",
        "singlevariable_normalizer.adapt(singlevariable)\n",
        "singlevariable_model = tf.keras.Sequential([singlevariable_normalizer,layers.Dense(units=1)])\n",
        "#singlevariable_model.summary()\n",
        "#singlevariable_model.predict(singlevariable[:10])\n",
        "singlevariable_model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.1),loss='mean_absolute_error')\n",
        "history = singlevariable_model.fit(train_features['input'], train_labels, verbose=0, epochs=100,validation_split = 0.2)\n",
        "# singlevariable_model.predict(singlevariable[:10])\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "print(hist.tail())\n",
        "#def plot_loss(history):\n",
        "#  plt.plot(history.history['loss'], label='loss')\n",
        "#  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "#  plt.ylim([0, 10])\n",
        "#  plt.xlabel('Epoch')\n",
        "#  plt.ylabel('Error [result]')\n",
        "#  plt.legend()\n",
        "#  plt.grid(True)\n",
        "#plot_loss(history)\n",
        "\n",
        "# test_results = {}\n",
        "# \n",
        "# test_results['singlevariable_model'] = singlevariable_model.evaluate(\n",
        "#     test_features['input'],\n",
        "#     test_labels, verbose=0)\n",
        "# \n",
        "# x = tf.linspace(0.0, 1, 10)\n",
        "# y = singlevariable_model.predict(x)\n",
        "# \n",
        "# def plot_singlevariable(x, y):\n",
        "#   plt.scatter(train_features['input'], train_labels, label='Data')\n",
        "#   plt.plot(x, y, color='k', label='Predictions')\n",
        "#   plt.xlabel('input')\n",
        "#   plt.ylabel('result')\n",
        "#   plt.legend()\n",
        "# \n",
        "# \n",
        "# plot_singlevariable(x,y)\n",
        "\n",
        "\n",
        "\n",
        "linear_model = tf.keras.Sequential([normalizer, layers.Dense(units=1)])\n",
        "\n",
        "#linear_model.layers[1].kernel\n",
        "\n",
        "linear_model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.1),loss='mean_absolute_error')\n",
        "\n",
        "history = linear_model.fit(\n",
        "    train_features, train_labels, \n",
        "    epochs=100,\n",
        "    # suppress logging\n",
        "    verbose=0,\n",
        "    # Calculate validation results on 20% of the training data\n",
        "    validation_split = 0.2)\n",
        "\n",
        "#plot_loss(history)\n",
        "#test_results['linear_model'] = linear_model.evaluate(test_features, test_labels, verbose=0)\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "print(hist.tail())\n",
        "\n",
        "\n",
        "def build_and_compile_model(norm):\n",
        "  model = keras.Sequential([\n",
        "      norm,\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  model.compile(loss='mean_absolute_error',\n",
        "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
        "  return model\n",
        "\n",
        "dnn_singlevariable_model = build_and_compile_model(singlevariable_normalizer)\n",
        "#dnn_singlevariable_model.summary()\n",
        "\n",
        "history = dnn_singlevariable_model.fit(\n",
        "    train_features['input'], train_labels,\n",
        "    validation_split=0.2,\n",
        "    verbose=0, epochs=100)\n",
        "\n",
        "#plot_loss(history)\n",
        "\n",
        "#x = tf.linspace(0.0, 250, 251)\n",
        "#y = dnn_singlevariable_model.predict(x)\n",
        "#plot_singlevariable(x, y)\n",
        "\n",
        "#test_results['dnn_singlevariable_model'] = dnn_singlevariable_model.evaluate(\n",
        "#    test_features['result'], test_labels,\n",
        "#    verbose=0)\n",
        "\n",
        "\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "print(hist.tail())\n",
        "\n",
        "dnn_model = build_and_compile_model(normalizer)\n",
        "#dnn_model.summary()\n",
        "\n",
        "\n",
        "history = dnn_model.fit(\n",
        "    train_features, train_labels,\n",
        "    validation_split=0.2,\n",
        "    verbose=0, epochs=100)\n",
        "\n",
        "#plot_loss(history)\n",
        "#test_results['dnn_model'] = dnn_model.evaluate(test_features, test_labels, verbose=0)\n",
        "#pd.DataFrame(test_results, index=['Mean absolute error [MPG]']).T\n",
        "#\n",
        "#test_predictions = dnn_model.predict(test_features).flatten()\n",
        "#\n",
        "#a = plt.axes(aspect='equal')\n",
        "#plt.scatter(test_labels, test_predictions)\n",
        "#plt.xlabel('True Values [MPG]')\n",
        "#plt.ylabel('Predictions [MPG]')\n",
        "#lims = [0, 50]\n",
        "#plt.xlim(lims)\n",
        "#plt.ylim(lims)\n",
        "#_ = plt.plot(lims, lims)\n",
        "#\n",
        "#error = test_predictions - test_labels\n",
        "#plt.hist(error, bins=25)\n",
        "#plt.xlabel('Prediction Error [MPG]')\n",
        "#_ = plt.ylabel('Count')\n",
        "\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "print(hist.tail())\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        loss  val_loss  epoch\n",
            "95  5.156955  5.450515     95\n",
            "96  5.184183  5.347929     96\n",
            "97  5.154091  5.487887     97\n",
            "98  5.265382  5.418309     98\n",
            "99  5.159566  5.536500     99\n",
            "        loss  val_loss  epoch\n",
            "95  0.065368  0.084601     95\n",
            "96  0.062945  0.064616     96\n",
            "97  0.063912  0.086809     97\n",
            "98  0.064824  0.080122     98\n",
            "99  0.061711  0.065190     99\n",
            "        loss  val_loss  epoch\n",
            "95  5.122212  5.309550     95\n",
            "96  5.116092  5.308816     96\n",
            "97  5.198895  5.363797     97\n",
            "98  5.162922  5.325118     98\n",
            "99  5.107795  5.295657     99\n",
            "        loss  val_loss  epoch\n",
            "95  0.021938  0.025670     95\n",
            "96  0.025304  0.021824     96\n",
            "97  0.027339  0.027454     97\n",
            "98  0.028432  0.042834     98\n",
            "99  0.029761  0.020880     99\n"
          ]
        }
      ]
    }
  ]
}